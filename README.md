# Amazon Product Analytics Dashboard

A comprehensive full-stack application for analyzing Amazon product data with AI-powered insights. This project demonstrates modern web development practices using Python FastAPI, Next.js, PostgreSQL with TimescaleDB, and AI integration.

## ğŸš€ Features

### Backend Features
- **FastAPI** REST API with automatic OpenAPI documentation
- **PostgreSQL** with **TimescaleDB** for time-series data
- **Redis** for caching and session management
- **SQLAlchemy 2.0** with async support
- **Alembic** database migrations
- **Pydantic** data validation and serialization
- **AI Integration** ready for OpenAI/Anthropic APIs

### Frontend Features
- **Next.js 14** with TypeScript
- **Tailwind CSS** for responsive design
- **React Query** for efficient data fetching
- **Recharts** for data visualization
- **Responsive dashboard** with modern UI components

### DevOps & Infrastructure
- **Docker** containerization
- **Docker Compose** for multi-service orchestration
- **Nginx** reverse proxy with rate limiting
- **Health checks** and monitoring
- **Development and production** configurations

## ğŸ›  Tech Stack

### Backend
- Python 3.11+
- FastAPI 0.104+
- PostgreSQL 15 with TimescaleDB
- Redis 7
- SQLAlchemy 2.0
- Alembic
- Pydantic 2.0

### Frontend
- Next.js 14
- TypeScript
- Tailwind CSS
- React Query
- Recharts
- Heroicons

### DevOps
- Docker & Docker Compose
- Nginx
- GitHub Actions (ready)

## ğŸ“¦ Project Structure

```
amazon-analytics/
â”œâ”€â”€ backend/                 # FastAPI backend application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/         # API routes and endpoints
â”‚   â”‚   â”œâ”€â”€ core/           # Configuration and settings
â”‚   â”‚   â”œâ”€â”€ db/             # Database configuration
â”‚   â”‚   â”œâ”€â”€ models/         # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ schemas/        # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic and services
â”‚   â”‚   â””â”€â”€ utils/          # Utility functions
â”‚   â”œâ”€â”€ alembic/            # Database migrations
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ Dockerfile          # Backend container configuration
â”œâ”€â”€ frontend/               # Next.js frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # Next.js app directory
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ lib/           # Utility libraries and API functions
â”‚   â”‚   â””â”€â”€ types/         # TypeScript type definitions
â”‚   â”œâ”€â”€ package.json       # Node.js dependencies
â”‚   â””â”€â”€ Dockerfile         # Frontend container configuration
â”œâ”€â”€ docker/                # Docker configuration files
â”‚   â”œâ”€â”€ nginx/             # Nginx configuration
â”‚   â””â”€â”€ postgres/          # PostgreSQL initialization
â”œâ”€â”€ scripts/               # Utility scripts
â””â”€â”€ docker-compose.yml     # Multi-service orchestration
```

## ğŸš€ Quick Start

### Prerequisites
- Docker and Docker Compose
- Node.js 18+ (for local development)
- Python 3.11+ (for local development)

### Option 1: Docker Development Environment

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd amazon-analytics
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

3. **Start development services**
   ```bash
   chmod +x scripts/start-dev.sh
   ./scripts/start-dev.sh
   ```

4. **Start backend (in separate terminal)**
   ```bash
   cd backend
   pip install -r requirements.txt
   uvicorn app.main:app --reload
   ```

5. **Start frontend (in separate terminal)**
   ```bash
   cd frontend
   npm install
   npm run dev
   ```

### Option 2: Full Docker Production Environment

1. **Set up environment**
   ```bash
   cp .env.example .env
   # Edit .env with your production configurations
   ```

2. **Start all services**
   ```bash
   chmod +x scripts/start-prod.sh
   ./scripts/start-prod.sh
   ```

## ğŸ”§ Configuration

### Environment Variables

#### Backend (.env)
```env
# Database
POSTGRES_SERVER=localhost
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password
POSTGRES_DB=amazon_analytics
POSTGRES_PORT=5432

# Redis
REDIS_URL=redis://localhost:6379

# Security
SECRET_KEY=your-secret-key-change-in-production
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI APIs (optional)
OPENAI_API_KEY=sk-your-openai-api-key
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key
```

#### Frontend (.env.local)
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“Š API Documentation

Once the backend is running, visit:
- **Interactive API docs**: http://localhost:8000/docs
- **ReDoc documentation**: http://localhost:8000/redoc
- **OpenAPI JSON**: http://localhost:8000/openapi.json

### Key API Endpoints

#### Products
- `GET /api/v1/products/` - List products with pagination
- `GET /api/v1/products/{asin}` - Get product details
- `POST /api/v1/products/` - Create new product
- `GET /api/v1/products/{asin}/price-history` - Price history

#### Analytics
- `GET /api/v1/analytics/overview` - Analytics overview
- `GET /api/v1/analytics/trends` - Trend data
- `GET /api/v1/analytics/top-products` - Top performing products

#### AI Services
- `POST /api/v1/ai/analyze-product` - AI product analysis
- `POST /api/v1/ai/generate-insights` - Generate insights from data
- `GET /api/v1/ai/health` - AI service health check

## ğŸ—„ Database Schema

### Core Tables
- **products** - Product information and metadata
- **price_history** - Historical pricing data (TimescaleDB hypertable)
- **product_analytics** - Analytics and performance metrics

### Key Features
- **TimescaleDB** for efficient time-series data handling
- **Automatic indexing** for optimal query performance
- **JSON columns** for flexible metadata storage

## ğŸ¤– AI Integration

The application is prepared for AI integration with:

### Supported AI Providers
- **OpenAI** (GPT models)
- **Anthropic** (Claude models)

### AI Features
- Product analysis and insights
- Trend analysis and predictions
- Automated recommendations
- Market intelligence

### Usage Example
```python
# Analyze a product
analysis = await ai_service.analyze_product(
    asin="B08N5WRWNW",
    analysis_type="comprehensive"
)

# Generate insights from data
insights = await ai_service.generate_insights(
    data=analytics_data,
    insight_type="trends"
)
```

## ğŸ§ª Testing

### Backend Testing
```bash
cd backend
pytest
```

### Frontend Testing
```bash
cd frontend
npm run test
npm run type-check
```

## ğŸ“ˆ Performance Optimization

### Backend Optimizations
- **Async/await** throughout the application
- **Connection pooling** for database connections
- **Redis caching** for frequently accessed data
- **Database indexing** for optimal query performance

### Frontend Optimizations
- **Next.js 14** with app directory
- **React Query** for efficient data fetching and caching
- **Code splitting** for optimal bundle sizes
- **Image optimization** with Next.js Image component

## ğŸ”’ Security Features

- **Input validation** with Pydantic
- **SQL injection protection** with SQLAlchemy
- **Rate limiting** with Nginx
- **CORS configuration**
- **Security headers**
- **Environment-based configuration**

## ğŸš€ Deployment

### Production Checklist
- [ ] Set strong `SECRET_KEY`
- [ ] Configure database credentials
- [ ] Set up SSL certificates
- [ ] Configure monitoring and logging
- [ ] Set up backup strategies
- [ ] Configure domain and DNS
- [ ] Set up CI/CD pipeline

### Scaling Considerations
- **Database scaling**: Read replicas, connection pooling
- **Application scaling**: Multiple backend instances
- **Caching**: Redis cluster for high availability
- **CDN**: For static assets and API responses
- **Monitoring**: Application performance monitoring

## ğŸ“‹ Development Workflow

1. **Create feature branch**
2. **Develop and test locally**
3. **Run tests and type checks**
4. **Update documentation**
5. **Create pull request**
6. **Deploy to staging**
7. **Deploy to production**

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Troubleshooting

### Common Issues

**Database Connection Issues**
```bash
# Check if PostgreSQL is running
docker-compose ps postgres

# View PostgreSQL logs
docker-compose logs postgres
```

**Frontend Build Issues**
```bash
# Clear cache and reinstall dependencies
rm -rf node_modules package-lock.json
npm install
```

**Backend Import Issues**
```bash
# Ensure PYTHONPATH is set correctly
export PYTHONPATH=$PYTHONPATH:$(pwd)
```

## ğŸ“ Support

For support and questions:
- Create an issue in the GitHub repository
- Check the documentation in the `/docs` directory
- Review API documentation at `/docs` endpoint

---

Built with â¤ï¸ for Amazon product analytics and business intelligence.